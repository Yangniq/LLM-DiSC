----------------------------------------------------------------------------------------------------
Starting interaction at 2025-02-02 06:22:13.183605
model: gpt-4o
temperature: 1
----------------------------------------------------------------------------------------------------
System:

You are an expert in designing controllers. Your task is to: 
- Analyze the given prompt and design a controller for the agent based on the provided information. 
- Implement the controller in Python, adhering to the specific format given in the prompt. 
- Ensure the controller enables the agent to avoid obstacles and other agents while successfully reaching its target.


User:

There are `10` homogeneous agents, each with a radius of `0.25`. The agents follow the dynamics $\dot{\boldsymbol{x} } =f(\boldsymbol{x}) + g(\boldsymbol{x}) \boldsymbol{u}$, where $\boldsymbol{x} = [p_x, p_y,\theta]$ represents the agent's position $(p_x,p_y)$ and orientation $\theta$ in a 2D space, and $\boldsymbol{u} = [v, \omega]$ represents the control inputs, with $v$ as the linear velocity and $\omega$ as the angular velocity. The initial states of the agents are`[[1.5, 0.5, 1.57], [3.5, 0.5, 1.57], [4.5, 0.5, 1.57], [6.5, 0.5, 1.57], [8.5, 0.5, 1.57], [9.5, 0.5, 1.57], [11.5, 0.5, 1.57], [14.5, 0.5, 1.57], [15.5, 0.5, 1.57], [18.5, 0.5, 1.57]]`, with their initial controls are `[[0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0]]`. Each agent has a known target point at `[[18, 19], [17, 19], [15, 19], [12, 19], [10, 19], [9, 19], [7.5, 19], [5, 19], [3, 19], [1, 19]]` (stop moving when the agent reaches the target point or gets sufficiently close to it). The positions of the obstacles are given as `[[(15.2, 8.3), (16.6, 12.0), (12.8, 12.6), (12.3, 11.9), (12.4, 9.0), (15.2, 8.3)], [(3.3, 6.8), (7.9, 6.3), (8.9, 7.6), (4.2, 8.0), (3.3, 6.8)], [(15.8, 2.5), (13.2, 6.4), (14, 3.2), (15.8, 2.5)], [(7.2, 11.2), (4.2, 17.4), (4.2, 12.0), (7.2, 11.2)], [(0.9, 5.2), (0.2, 3.2), (1.2, 1.8), (2.4, 1.3), (0.9, 5.2)], [(17.5, 6.1), (19.4, 5.3), (19.8, 5.8), (18.1, 6.1), (17.5, 6.1)]]`, each sublist represents the vertices of a polygon, with each vertex stored in the form of `(x, y)`. The last vertex is the same as the first, indicating a closed polygon.

Please help design a controller and implement it as Python function. The function should output the control input signal needed to update the agent's state. The time interval for the agent's state update is `0.05`. The function should return the control signal. Please design the controller using the following Python function structure and do not need the `example usage`:

```
def get_control(index,all_state,all_ctrl,target_pos,obs_pos,agent_R, state_info):
        # Your code to compute the control input
        return control_input
```

Where:

- 'index' is the agent index, starting from 0.
- 'all_state' is the current state of all the agents in the format [[x1, y1,theta1], [x2, y2,theta2], ...].
- 'all_ctrl' is the control signal of the agent in the format [[v1, omega1], [v2, omega2], ...].
- 'target_pos' is the target position of the agent in the format [x, y].
- 'obs_pos' is a list containing the vertex coordinates of multiple polygons, formatted as [[(x1,y1),(x2,y2),...,(x1,y1)],[...],...]. Each sublist represents the vertices of a polygon, the last vertex is the same as the first, indicating a closed polygon.
- 'agent_R' is the radius of the agent.
- 'state_info' is the state change of all agents from the initial moment to the current moment, formatted as [[[x11, y11,theta11], [x12, y12,theta12],...], [[x21, y21,theta21], [x22, y22,theta22],...],...]. (For example, `state_info[index]` records the state change of the agent `index` from the initial moment to the current moment.)



Assistant:
We need to design a controller for the agent to steer them towards their respective target points while considering obstacle avoidance and avoiding collisions with other agents. The dynamics of the agents are given by the equation $\dot{\boldsymbol{x} } =f(\boldsymbol{x}) + g(\boldsymbol{x}) \boldsymbol{u}$, where $\boldsymbol{u} = [v, \omega]$ represents the control inputs (linear and angular velocities).

To achieve this, we'll use a combination of proportional control and potential field methods:

1. **Proportional Control** for target tracking.
2. **Artificial Potential Fields** for obstacle avoidance.

The proportional controller will ensure the agent moves towards its target, while the artificial potential field will generate repulsive forces to keep the agent away from obstacles and other agents.

Here's how we can implement this in the `get_control` function:

```python
import numpy as np

def get_control(index, all_state, all_ctrl, target_pos, obs_pos, agent_R, state_info):
    params = {
        'k_v': 1.0,  # Proportional gain for linear velocity
        'k_omega': 1.5,  # Proportional gain for angular velocity
        'obs_r': 1.0,  # Radius of influence for obstacles
        'agent_r': agent_R * 2,  # Safe distance from other agents
        'v_max': 1.0,  # Maximum linear velocity
        'omega_max': np.pi,  # Maximum angular velocity
    }

    def wrap_angle(theta):
        return np.arctan2(np.sin(theta), np.cos(theta))

    def compute_repulsive_force(agent_pos, obstacle_vertices, influence_radius):
        force = np.zeros(2)
        for i in range(len(obstacle_vertices) - 1):  # looping through each edge of the polygon
            obs_edge_start = np.array(obstacle_vertices[i])
            obs_edge_end = np.array(obstacle_vertices[i + 1])
            edge_vect = obs_edge_end - obs_edge_start
            agent_vect = agent_pos - obs_edge_start
            edge_length = np.linalg.norm(edge_vect)
            if edge_length > 0:
                edge_unit_vect = edge_vect / edge_length
                proj_length = np.dot(agent_vect, edge_unit_vect)
                if 0 <= proj_length <= edge_length:
                    closest_point = obs_edge_start + proj_length * edge_unit_vect
                else:
                    closest_point = obs_edge_start if proj_length < 0 else obs_edge_end
                dist = np.linalg.norm(agent_pos - closest_point)
                if dist < influence_radius:
                    repulsion = (influence_radius - dist) / influence_radius * (agent_pos - closest_point) / dist
                    force += repulsion
        return force

    current_pos = np.array(all_state[index][:2])
    current_theta = all_state[index][2]

    # Calculating attractive force towards target
    target_vector = np.array(target_pos) - current_pos
    theta_target = np.arctan2(target_vector[1], target_vector[0])
    dist_to_target = np.linalg.norm(target_vector)
    
    if dist_to_target < 0.1:  # Close enough to the target
        return [0, 0]

    # Computing repulsive forces from obstacles
    repulsive_force = np.zeros(2)
    for obstacle in obs_pos:
        repulsive_force += compute_repulsive_force(current_pos, obstacle, params['obs_r'])

    # Computing repulsive forces from other agents
    for i, state in enumerate(all_state):
        if i != index:
            other_agent_pos = np.array(state[:2])
            dist_to_agent = np.linalg.norm(current_pos - other_agent_pos)
            if dist_to_agent < params['agent_r']:
                repulsion = (params['agent_r'] - dist_to_agent) / params['agent_r'] * (current_pos - other_agent_pos) / dist_to_agent
                repulsive_force += repulsion

    total_force = target_vector / dist_to_target + repulsive_force
    theta_desired = np.arctan2(total_force[1], total_force[0])

    # Calculating controls
    v = params['k_v'] * dist_to_target
    omega = params['k_omega'] * wrap_angle(theta_desired - current_theta)

    v = np.clip(v, -params['v_max'], params['v_max'])
    omega = np.clip(omega, -params['omega_max'], params['omega_max'])

    return [v, omega]
```

In this controller:

- We're using a proportional controller to generate an attractive force towards the target position.
- An artificial potential field generates repulsive forces to avoid obstacles and nearby agents.
- The velocity and angular velocity commands are computed from the resultant force direction and distance to the target while considering maximum limits for safety.

This ensures that the agents navigate towards their respective targets efficiently while avoiding obstacles along the way.

